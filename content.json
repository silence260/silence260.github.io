{"meta":{"title":null,"subtitle":null,"description":null,"author":"Wei","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"iOS 开发中的 Bitcode","slug":"iOS 开发中的 Bitcode","date":"2019-08-12T12:53:40.000Z","updated":"2019-08-14T14:45:43.472Z","comments":true,"path":"2019/08/12/iOS 开发中的 Bitcode/","link":"","permalink":"http://yoursite.com/2019/08/12/iOS 开发中的 Bitcode/","excerpt":"","text":"Bitcode 是什么，有什么作用 Xcode 7 之后，在我们新建一个 iOS 项目时，Bitcode 选项默认是设置为 YES 的。我们可以在 ”Build Settings” -&gt; ”Enable Bitcode” 中看到这个设置项。 Apple 目前采用的编译器工具链是 LLVM，我们在编辑器中通过 C/C++/Objective-c/Swift 等语言编写的程序，通过 LLVM 编译器编译为各个芯片平台上的汇编指令，或可执行机器指令数据。而 Bitcode 则是位于编译前后之间的一种中间码。 LLVM 的编译工作原理是先把项目程序源代码翻译为 Bitcode 中间码；再根据不同目标机器芯片平台，转换为相应的汇编指令及机器码。这样的设计就让 LLVM 成为了一个编译器架构，可以轻而易举的在 LLVM 架构之上发明新的语言，以及在 LLVM 架构下支持新的 CPU 指令输出。虽然 Bitcode 仅仅只是一个中间码，不能在任何平台上运行，但它可以转化为任何被支持的 CPU 指令，包括还没被发明的 CPU。 也就是说现在打开 Bitcode 功能，提交一个 App 到 App Store。如果后面 Apple 推出了一款 CPU 全新设计的手机，在苹果后台服务器一样可以通过这个 App 的 Bitcode 编译转化为适用于新 CPU 的可执行程序，以供新手机用户下载运行这个 App。 @Onevcat 在 开发者所需要知道的 iOS 9 SDK 新特性，对 Bitcode 有这样的介绍。 给 App 瘦身的另一个手段是提交 Bitcode 给 Apple，而不是最终的二进制。Bitcode 是 LLVM 的中间码，在编译器更新时，Apple 可以用你之前提交的 Bitcode 进行优化，这样你就不必在编译器更新后再次提交你的 app，也能享受到编译器改进所带来的好处。Bitcode 支持在新项目中是默认开启的，没有特别理由的话，你也不需要将它特意关掉。 Bitcode 支持哪些平台列出 iOS、WatchOS、TVOS 及 macOS 对 Bitcode 的支持情况： 对于 iOS 平台，Bitcode 是可选的；对于 WatchOS 及 TVOS，Bitcode 是必须开启的；对于 macOS，是不支持 Bitcode 的. Bitcode 的优缺点优点 Bitcode 上传到 Apple 服务器后，Apple 为安装 App 的目标设备进行二进制优化，减少安装包的下载大小;Apple 以后如果设计了采用新指令集的新 CPU，可以继续使用同一份 Bitcode 编译出新 CPU 上执行的可执行文件，供新设备用户下载安装；缺点 使用了 Bitcode 之后，用户安装的二进制不是开发者这边生成的，而是 Apple 服务器经过优化生成的二进制，对于开发者来说，丢失了对应的调试符号信息 总结由阿里百川用户反馈模块集成遇到的一个 Bitcode 问题。单纯对于用户反馈这项功能来说，很好奇的一点是，通过手动引入 Framework 没有遇到 Bitcode 不支持的问题；而通过 Cocoapods 引入，遇到了前面提到的 Bitcode 问题。考虑到项目的后期维护性，最终选用的解决方案是，通过 Cocoapods 引入库，同时关闭 Bitcode 的支持。 转载自链接：https://github.com/JonyFang/dev-notes","categories":[],"tags":[]},{"title":"搭建iOS端视频直播系统","slug":"搭建iOS端视频直播系统","date":"2019-08-11T11:22:33.000Z","updated":"2019-08-14T14:46:06.945Z","comments":true,"path":"2019/08/11/搭建iOS端视频直播系统/","link":"","permalink":"http://yoursite.com/2019/08/11/搭建iOS端视频直播系统/","excerpt":"","text":"本文主要使用的三个技术：推流：LFLiveKit播放：ijkplayer服务器:nginx+rtmp+ffmpeg 一、推流LFLiveKit：框架支持RTMP，由Adobe公司开发。github地址https://github.com/LaiFengiOS/LFLiveKitLFLiveKit库里已经集成GPUImage框架用于美颜功能，GPUImage基于OpenGl开发，纯OC语言框架，封装好了各种滤镜同时也可以编写自定义的滤镜，其本身内置了多达125种常见的滤镜效果。 二、播放ijkplayer：是基于FFmpeg的跨平台播放器框架，由B站开发。目前已被多个主流直播App集成使用。github地址：https://github.com/Bilibili/ijkplayer 三、服务器搭建nginx+rtmp+ffmpeg：在本地搭建服务器，免去开通第三方直播的流量费用。现在我们的项目中集成了推流的所用的LFLiveKit，播放所需的ijkplayer，便可用手机做推流直播，模拟器做拉流播放。 四、总结一个完整的直播系统需要涉及到的技术主要包括以下方面：1.采集、2.滤镜处理、3.编码、4.推流、5.CDN分发、6.拉流、7.解码、8.播放、9.聊天互动。其中1～4由LFLiveKit完成（2由GPUImage完成），5就是搭建的本地服务器，6～8由ijkplayer完成。 转载自链接：https://www.jianshu.com/p/30595a5bff42","categories":[],"tags":[]}]}